Class 5 :

A pipline is a set of jobs which are executed one after another

sytemctl start jenkins

*****

http://18.118.10.14:8080/github-webhook/
http://Jenkins-url/github-webhook/

--------------------------------------------------------------------

Class 6:

1)core build plugins 2) report plugins

pmd - programming mistake detector

sample java project : 
1) https://github.com/Sonal0409/DevOpsCodeDemo.git
2) https://github.com/Sonal0409/JavaWebCalculator (incomple pom file)
3) https://github.com/Sonal0409/calcwebapp-sonar.git

pom file consists of 
1)dependicies 

2)plugins 

2)repositorys - are registries from which maven will download the plug in or dependecies

for graddel - build.xml 
for maven pom.xml

manage jenkins - setup maven ny using jenkins

cd --> /var/lib/jenkins   -> hudson.tasks.Maven.xml

1) package 

maven commands are case sensitive

-----------

pipeline {
    
    tools {
        maven 'mymaven'
    }
    
    //here any means execute the pipline on any of the available servers i.e. current VM for now
    agent any
    
    stages {
        
        stage ('Clone Repo') {
            
            steps {
                git 'https://github.com/vjdgithub/DevOpsCodeDemo.git'
            }
            
        }
        
        stage ('Compile Code') {
            
            steps {
                sh 'mvn compile'
            }
            
        }
        
        stage ('Test Code') {
            
            steps {
                sh 'mvn test'
            }
            
        }
        
        stage ('Package Code') {
            
            steps {
                sh 'mvn package'
            }
            
        }
    }
    
}

-------------------------------------------------------------

Class 7:

for review 

stage ('Review Code') {
            
            steps {
                sh 'mvn pmd:pmd'
            }
            
        }

gives pmd.xml  -  all the development mistakes will be here

for coverage - based on the test cases how much code is covered for testeing - jacoco plug in

repository to support cove coverage

https://github.com/vjdgithub/calcwebapp-sonar.git

code coverage is a process in which we generate a report using code coverage tool (ie. jacoco or cobertura etc..) against compiled classes and test cases which helps us to determine which part of java programme has been tetsted and which part lacks testing

code coverage report will be generatd 

unit testing - developer

and testing team - selenium, Cypress and jasmine testing tools for testers   
integration testing - 

performnce testing Jmeter, load runner to write the test cases

all of the above integrated with jenkins

link for .net project - https://github.com/vjdgithub/MSbuildProject.git

https://github.com/vjdgithub/DevOps_ClassNotes/blob/master/JENKINS/MSBuildJenkins.docx
 
parameters are variable which can store values, Dev , Prod - we can choose ad based on parameter i can execute the stage 

boolean or choice parameter

parameters are declared in the parameters section and used in stages for conditions

concept of backing up the jenkins server - s3 bucket

triggers in a pipeline

https://github.com/vjdgithub/DevOps_ClassNotes/blob/master/JENKINS/Triggers_PIPELINE

pipeline {
    
    tools {
        
        maven 'mymaven'
    }
    
    agent any
    
    //parameter that stores set of values --> parameter type = choice
    // default value will be given for choice
    parameters {
        
        choice(name: "ENV", choices: ["", "Dev", "QA"])
    }
    
    stages {
        
        stage("Build in Dev Env"){
            
            when { expression {params.ENV == "Dev"}}
            steps{
                
               git 'https://github.com/vjdgithub/DevOpsCodeDemo.git'
               sh 'mvn pmd:pmd'
               sh 'mvn package'
            }
            
        }
        
        stage("Build in QA Env"){
            
            when { expression {params.ENV == "QA"}}
            steps{
                
               git 'https://github.com/vjdgithub/DevOpsCodeDemo.git'
               sh 'mvn test'
               sh 'mvn package'
            }
            
        }
    }
    
}

Slave Set up :
---------------
yum install git -y
sudo amazon-linux-extras install java-openjdk11 -y
go to tmp folder create jenkins directory
cd /tmp
mkdir jenkinsdir
give jenkinsdir with read and write permissions
chmod -R 777 /tmp/jenkinsdir

change the name of the machine to JenkinsAgent

hostname JenkinsAgent
sudo su -

Agent should be enabled to Random in Manage Jenkins/Security

configure the agents to the master
 manual setup via nodes or on the cloud automatically
no use manual setup in using nodes in configuration 

labels are used for selecting the desired VM on the linux

use it to build the jobs on maching lable expressions

host address is private ip as both the instances are in the same network


--jfrog artifactory conncet using ssh and deply artifacts

all the jobs run on any node labled 'linux_node'

pipeline {
    
    tools {
        maven 'mymaven'
    }
    
    //here any means execute the pipline on any of the available servers i.e. current VM for now
    agent { label 'linux_node'  }
    
    stages {
        
        stage ('Clone Repo') {
            
            steps {
                git 'https://github.com/vjdgithub/DevOpsCodeDemo.git'
            }
            
        }
        
        stage ('Compile Code') {
            
            steps {
                sh 'mvn compile'
            }
            
        }
        
        stage ('Review Code') {
            
            steps {
                sh 'mvn pmd:pmd'
            }
            
        }
        
        stage ('Test Code') {
            
            steps {
                sh 'mvn test'
            }
            
        }
        
        stage ('Package Code') {
            
            steps {
                sh 'mvn package'
            }
            
        }
    }
    
}

One job on Master server and one job on the any node labled 'linux_node'

pipeline {
    
    tools {
        
        maven 'mymaven'
    }
    
    agent none
    
    //parameter that stores set of values --> parameter type = choice
    // default value will be given for choice
    parameters {
        
        choice(name: "ENV", choices: ["", "Dev", "QA"])
    }
    
    stages {
        
        stage("Build in Dev Env"){
            
            agent { label 'linux_node'  }
            
            when { expression {params.ENV == "Dev"}}
            steps{
                
               git 'https://github.com/vjdgithub/DevOpsCodeDemo.git'
               sh 'mvn pmd:pmd'
               sh 'mvn package'
            }
            
        }
        
        stage("Build in QA Env"){
            
            agent any
            
            when { expression {params.ENV == "QA"}}
            steps{
                
               git 'https://github.com/vjdgithub/DevOpsCodeDemo.git'
               sh 'mvn test'
               sh 'mvn package'
            }
            
        }
    }
    
}

//how to set up windos slave

https://github.com/vjdgithub/DevOps_ClassNotes/blob/master/JENKINS/MVNJENKINS_NOTES.txt

----------
Class 8 :

Dockerhub - it is a online open source repository where Docker places its images which is binary file

yum install docker -y

systectl start docker

docker info

private registries are maintained by docker administrator

Registry - a location to maintain binary file
Repository - a location to maintain source code

//to check the images
docker images

docker pull ubantu

//to check the all the container
docker ps -a 

//to check the running container
docker ps 

docker login -u <your-username>

docker login -u vjddocker 

You may need to use a specific registry version, for me this worked.
docker login registry-1.docker.io/v1

Ansible docker is primarly only for linux

for pulling no need of username and pwd but for pushing it requires

tags are different versions of the images

an image is built by using editable docker file when ever you build a new image new version of the image is introduced that is called a s tag. 

//to pull specific version
docker pull imagename:tagname

//for pulling puclic images you do not need credentials
docker pull sonal04/base01 

 docker run ubuntu

when we run image again every time new container will come

docker run is a dual command - first check if image is avaiable locally or not otherwise get it will pull and create the container
//ceate a container with name
docker run --name <containerName> imageName
docker run --name cont1 ubuntu

//for user to be attached to the container in foreground mode use -it
docker run --name cont2 -it ubuntu

container id and name are unique

//to know the os 
cat /etc/os-release

--you can not run docker commands on the container -- docker wont install in container

--come out of the container and keep the container running
CTL pq

---to attach to the container again - you can attach only to a running container
docker attach containername

--when we exit we come out of the container and container exited
-- we can start containers again only which are created in forground mode
docker start containername
-- to stop the container
docker stop containername

-- you can not run windows container on linux and vice versa

- for every service it is a micro service i.e. your application is running independent of the others
- for ecommerce application you will create may services i.e. containers

---
to delete the container
docker rm -f <containername?
---to delete all  the containers
docker rm -f $(docker ps -aq)

------------
class 9 :
-----------
Access the container in detached mode (-d)

dangling images - images in the machine without a container attached

to remove the dangling images command is 
docker system prune
docker system prune --all

docker system prune --images [to remove only images]

to inspect if there are any containers attached the command is

docker inspect <imagename>

to create nginx image with a name in a detached mode

docket run --name web -d nginx

you can acces the detached container i.e. web containers from the host machine and out side of host machine also i.e via internet

to access the container from the host machine and execute a command as   

docker exce  -it<for attachment> <containername> <command>

docker exec -it web /bin/bash

by default nginx container comes with application

 cd usr/share/nginx
 ls
 cd html
 there is default index page
when i exit i am out of the process and container is still running

to acceess that applicaion we need use concept of port mapping/port forwarding

every we container will have a port number attached with it

** port mapping needs to done at the docker run command itself

---in docker once the container is created we can not do port mapping but in kubernatics we can do 

docker run --name web2 -d -p 9090:80 nginx

or let docker decide the port number

docker run --name web3 -d -P(CAPITAL P) nginx
docker run --name web3 -d -P nginx

---when even when docker is installed by default docker creates its own network as Docker zero network (type bridge) it has a default sub net range and the container get ip addresses of that sub net range

--we can not access the container via ip but can ccess by mapped port number

-- docker that container is created in production environment via archestration tool will have port number in the range of 30000 to 32767

to know the network

docker network ls 

-------

customize the container and convert in to a image

come out of the container CTL + p



docker commit basecont myimage01

docker login 

docker push image01 - access denied as you are pushing to docker hub library

hence change the image name as 

docker tag <OldImageName> <DockerAccountId/NewImageName> 

docker tag myimage01 vjddocker/myiamge01
docker push vjddocker/myiamge01

recent interview questions :

what are dangling images 
how to push docker into a aws private registry - vedio recording is there
difference between docker stocp and kill command 

-----
Class 10
-----

before writing a docker file plan first waht you need in container

by default Run commands run in the root directory otherwise you can choose

What is the difference between Copy and Add keyworks

docker build . (. means current directory-> build command allways searches for dockerfile) other specify the path as below
docker build -p /path/file

if  we want to tag the image as below

docker build -t myimage01:tag .

--image is a collection of binary files . these set of images together consistitues final image
-- docker at commits images one by one -- commit is what  uses in the background and what ever activities what docker is using to build your final image is docker cache

docker build -t myimage01:tag . 

in one directory only one docker file should be there
you need not give the name of the dockerfile as the file name is always dockerfile
by default docker docker doesnot validate the dockerfile . errors come runtime. however there is one dockerfile linter and you can validate the dockerfile

docker history <imagename>/<imageid>

when we delete an image iamge layers shown in the docker history will be be deleted but not docker cache. if you wanrt to delete the docker cache you need to use below caommand

docker system prune --all

Difference between CMD and ENTRYPOINT Keywords

both will execute after the instance is launched

between CMD and ENTRYPOINT --> ENTRYPOINT gets precedence - it is the final command

In the dockerfile if the developer mentions only CMD that means the the docker developer is giving an oppertunity to the another deveoper who is running the image to pass a new command at run time. so when i run the busybox image if i dont want default to be "sh" and if i want some other command to be given at runtime after the container is launched a below

actual busybox dockerfile is 

FROM scratch
ADD busybox.tar.xz /
CMD ["sh"]

docker run -d busybox sleep 6000

above "sh" command is replaced with "sleep 6000" at run time

if it is placed in at entry point then that command can not be replaced by entrypoint command. but when we pass new command at run time when docker file using entrypoint, the newly given command at run time is just gets appended to the entry point command.

docker run -d nginx slep 6000 

how to create multi stage Build dockerfile - home work

------
Class 11
------

Deploy a node js application using image node from

https://github.com/Sonal0409/nodejsappDockerfile.git

we can not do port mapping in the dockerfile . while creating container only we need to port mapping

docker system prune --all
docker rm -f $(docker ps -aq)

clone the above repo and go inside the repo, remove all the existing images and processes and then do the following

docker build -t mynodeapp .

docker run -d -P mynodeapp

docker ps -a

press enter to execute the command
press CTL + C - to dont run and come out

on our server does not have root permissions to run docker command

got to /etc/sudoers file, inside this file go to root section and give jenkins user nopassword permission as below

jenkins ALL=NOPASSWD: ALL

or you can run a command to give permission to run docker by any user as below

chmod 777 /var/run/docker.sock 

pipeline {
    
    tools {maven 'mymaven'}
    
    agent any 
    
    stages {
        
        stage ('Clone Repo') {
            
            steps {
                git 'https://github.com/vjdgithub/DevOpsCodeDemo.git'
            }
            
        }
        
        stage ('Compile Code') {
            
            steps {
                sh 'mvn compile'
            }
            
        }
        
        stage ('Review Code') {
            
            steps {
                sh 'mvn pmd:pmd'
            }
            
        }
        
        stage ('Test Code') {
            
            steps {
                sh 'mvn test'
            }
            
        }
        
        stage ('Package Code') {
            
            steps {
                sh 'mvn clean install package'
            }
            
        }
        
        stage ('Copy the War file from target directory to current diroctory') {
            
            steps {
                sh 'cp /var/lib/jenkins/workspace/CICDpipeline/target/addressbook.war .'
            }
            
        }
        stage ('Build Image') {
            
            steps {
                sh 'docker build -t myappjenkins .'
            }
            
        }
        stage ('Deploy the Image') {
            
            steps {
                sh 'docker run -d -P myappjenkins'
            }
            
        }
        
    }
}

for java application deployed in tomcat access the appliacation appended with war file name as below

http://18.223.171.192:32769/addressbook

------












